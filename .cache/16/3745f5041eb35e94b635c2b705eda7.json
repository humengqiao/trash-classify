{"id":"sbhA","dependencies":[{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/package.json","includedInParent":true,"mtime":1609565602436},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":499162500000},{"name":"@tensorflow/tfjs-core","loc":{"line":14,"column":36},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/index.js"},{"name":"../activations","loc":{"line":15,"column":51},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/activations.js"},{"name":"../backend/common","loc":{"line":16,"column":32},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/backend/common.js"},{"name":"../backend/tfjs_backend","loc":{"line":17,"column":19},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/backend/tfjs_backend.js"},{"name":"../common","loc":{"line":18,"column":50},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/common.js"},{"name":"../constraints","loc":{"line":19,"column":51},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/constraints.js"},{"name":"../engine/topology","loc":{"line":20,"column":33},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js"},{"name":"../errors","loc":{"line":21,"column":48},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/errors.js"},{"name":"../initializers","loc":{"line":22,"column":53},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/initializers.js"},{"name":"../regularizers","loc":{"line":23,"column":53},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/regularizers.js"},{"name":"../utils/conv_utils","loc":{"line":24,"column":63},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/conv_utils.js"},{"name":"../utils/generic_utils","loc":{"line":25,"column":31},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/generic_utils.js"},{"name":"../utils/types_utils","loc":{"line":26,"column":56},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/types_utils.js"}],"generated":{"js":"\"use strict\";Object.defineProperty(exports,\"__esModule\",{value:!0}),exports.preprocessConv2DInput=f,exports.preprocessConv3DInput=m,exports.conv1dWithBias=z,exports.conv1d=b,exports.conv2d=v,exports.conv2dWithBiasActivation=k,exports.conv3d=w,exports.conv3dWithBias=C,exports.UpSampling2D=exports.Cropping2D=exports.Conv1D=exports.SeparableConv2D=exports.SeparableConv=exports.Conv2DTranspose=exports.Conv3D=exports.Conv2D=exports.Conv=exports.BaseConv=void 0;var e=g(require(\"@tensorflow/tfjs-core\")),t=require(\"../activations\"),i=require(\"../backend/common\"),r=g(require(\"../backend/tfjs_backend\")),n=require(\"../common\"),s=require(\"../constraints\"),a=require(\"../engine/topology\"),o=require(\"../errors\"),l=require(\"../initializers\"),h=require(\"../regularizers\"),p=require(\"../utils/conv_utils\"),d=g(require(\"../utils/generic_utils\")),u=require(\"../utils/types_utils\");function c(){if(\"function\"!=typeof WeakMap)return null;var e=new WeakMap;return c=function(){return e},e}function g(e){if(e&&e.__esModule)return e;if(null===e||\"object\"!=typeof e&&\"function\"!=typeof e)return{default:e};var t=c();if(t&&t.has(e))return t.get(e);var i={},r=Object.defineProperty&&Object.getOwnPropertyDescriptor;for(var n in e)if(Object.prototype.hasOwnProperty.call(e,n)){var s=r?Object.getOwnPropertyDescriptor(e,n):null;s&&(s.get||s.set)?Object.defineProperty(i,n,s):i[n]=e[n]}return i.default=e,t&&t.set(e,i),i}function f(t,i){return(0,e.tidy)(()=>((0,n.checkDataFormat)(i),\"channelsFirst\"===i?e.transpose(t,[0,2,3,1]):t))}function m(t,i){return(0,e.tidy)(()=>((0,n.checkDataFormat)(i),\"channelsFirst\"===i?e.transpose(t,[0,2,3,4,1]):t))}function z(t,s,a,l=1,h=\"valid\",p,d=1){return(0,e.tidy)(()=>{if(null==p&&(p=(0,i.imageDataFormat)()),(0,n.checkDataFormat)(p),3!==t.shape.length)throw new o.ValueError(\"The input of a conv1dWithBias operation should be 3, but is \"+`${t.shape.length} instead.`);if(3!==s.shape.length)throw new o.ValueError(\"The kernel for a conv1dWithBias operation should be 3, but is \"+`${s.shape.length} instead`);if(null!=a&&1!==a.shape.length)throw new o.ValueError(\"The bias for a conv1dWithBias operation should be 1, but is \"+`${s.shape.length} instead`);if(\"channelsFirst\"===p&&(t=e.transpose(t,[0,2,1])),\"causal\"===h)throw new o.NotImplementedError(\"The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.\");let u=e.conv1d(t,s,l,\"same\"===h?\"same\":\"valid\",\"NWC\",d);return null!=a&&(u=r.biasAdd(u,a)),u})}function b(t,i,r=1,s=\"valid\",a,o=1){return(0,e.tidy)(()=>((0,n.checkDataFormat)(a),z(t,i,null,r,s,a,o)))}function v(t,i,r=[1,1],s=\"valid\",a,o){return(0,e.tidy)(()=>((0,n.checkDataFormat)(a),k(t,i,null,r,s,a,o)))}function k(t,r,s,a=[1,1],l=\"valid\",h,p,d=null){return(0,e.tidy)(()=>{if(null==h&&(h=(0,i.imageDataFormat)()),(0,n.checkDataFormat)(h),3!==t.rank&&4!==t.rank)throw new o.ValueError(\"conv2dWithBiasActivation expects input to be of rank 3 or 4, \"+`but received ${t.rank}.`);if(3!==r.rank&&4!==r.rank)throw new o.ValueError(\"conv2dWithBiasActivation expects kernel to be of rank 3 or 4, \"+`but received ${t.rank}.`);let u=f(t,h);if(\"causal\"===l)throw new o.NotImplementedError(\"The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.\");return u=e.fused.conv2d({x:u,filter:r,strides:a,pad:\"same\"===l?\"same\":\"valid\",dilations:p,dataFormat:\"NHWC\",bias:s,activation:d}),\"channelsFirst\"===h&&(u=e.transpose(u,[0,3,1,2])),u})}function w(t,i,r=[1,1,1],s=\"valid\",a,o){return(0,e.tidy)(()=>((0,n.checkDataFormat)(a),C(t,i,null,r,s,a,o)))}function C(t,s,a,l=[1,1,1],h=\"valid\",p,d){return(0,e.tidy)(()=>{if(null==p&&(p=(0,i.imageDataFormat)()),(0,n.checkDataFormat)(p),4!==t.rank&&5!==t.rank)throw new o.ValueError(\"conv3dWithBias expects input to be of rank 4 or 5, but received \"+`${t.rank}.`);if(4!==s.rank&&5!==s.rank)throw new o.ValueError(\"conv3dWithBias expects kernel to be of rank 4 or 5, but received \"+`${t.rank}.`);let u=m(t,p);if(\"causal\"===h)throw new o.NotImplementedError(\"The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.\");return u=e.conv3d(u,s,l,\"same\"===h?\"same\":\"valid\",\"NDHWC\",d),null!=a&&(u=r.biasAdd(u,a)),\"channelsFirst\"===p&&(u=e.transpose(u,[0,4,1,2,3])),u})}class y extends a.Layer{constructor(e,i){if(super(i),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER=\"glorotNormal\",this.DEFAULT_BIAS_INITIALIZER=\"zeros\",y.verifyArgs(i),this.rank=e,d.assertPositiveInteger(this.rank,\"rank\"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new o.NotImplementedError(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is `+\"not implemented yet.\");if(this.kernelSize=(0,p.normalizeArray)(i.kernelSize,e,\"kernelSize\"),this.strides=(0,p.normalizeArray)(null==i.strides?1:i.strides,e,\"strides\"),this.padding=null==i.padding?\"valid\":i.padding,(0,n.checkPaddingMode)(this.padding),this.dataFormat=null==i.dataFormat?\"channelsLast\":i.dataFormat,(0,n.checkDataFormat)(this.dataFormat),this.activation=(0,t.getActivation)(i.activation),this.useBias=null==i.useBias||i.useBias,this.biasInitializer=(0,l.getInitializer)(i.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=(0,s.getConstraint)(i.biasConstraint),this.biasRegularizer=(0,h.getRegularizer)(i.biasRegularizer),this.activityRegularizer=(0,h.getRegularizer)(i.activityRegularizer),this.dilationRate=(0,p.normalizeArray)(null==i.dilationRate?1:i.dilationRate,e,\"dilationRate\"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new o.ValueError(\"dilationRate must be a number or an array of a single number for 1D convolution, but received \"+`${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if(\"number\"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new o.ValueError(\"dilationRate must be a number or array of two numbers for 2D \"+`convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank)if(\"number\"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new o.ValueError(\"dilationRate must be a number or array of three numbers for 3D \"+`convolution, but received ${JSON.stringify(this.dilationRate)}`)}static verifyArgs(e){if(d.assert(\"kernelSize\"in e,\"required key 'kernelSize' not in config\"),\"number\"!=typeof e.kernelSize&&!d.checkArrayTypeAndLength(e.kernelSize,\"number\",1,3))throw new o.ValueError(\"BaseConv expects config.kernelSize to be number or number[] with \"+`length 1, 2, or 3, but received ${JSON.stringify(e.kernelSize)}.`)}getConfig(){const e={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:(0,t.serializeActivation)(this.activation),useBias:this.useBias,biasInitializer:(0,l.serializeInitializer)(this.biasInitializer),biasRegularizer:(0,h.serializeRegularizer)(this.biasRegularizer),activityRegularizer:(0,h.serializeRegularizer)(this.activityRegularizer),biasConstraint:(0,s.serializeConstraint)(this.biasConstraint)},i=super.getConfig();return Object.assign(e,i),e}}exports.BaseConv=y;class I extends y{constructor(e,t){super(e,t),this.kernel=null,I.verifyArgs(t),this.filters=t.filters,d.assertPositiveInteger(this.filters,\"filters\"),this.kernelInitializer=(0,l.getInitializer)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=(0,s.getConstraint)(t.kernelConstraint),this.kernelRegularizer=(0,h.getRegularizer)(t.kernelRegularizer)}build(e){e=(0,u.getExactlyOneShape)(e);const t=\"channelsFirst\"===this.dataFormat?1:e.length-1;if(null==e[t])throw new o.ValueError(\"The channel dimension of the input should be defined. \"+`Found ${e[t]}`);const i=e[t],r=this.kernelSize.concat([i,this.filters]);this.kernel=this.addWeight(\"kernel\",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight(\"bias\",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[t]:i}}],this.built=!0}call(t,i){return(0,e.tidy)(()=>{let e;t=(0,u.getExactlyOneTensor)(t);const i=null==this.bias?null:this.bias.read(),r=d.mapActivationToFusedKernel(this.activation.getClassName());if(null!=r&&2===this.rank)e=k(t,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate,r);else{if(1===this.rank)e=z(t,this.kernel.read(),i,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)e=k(t,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new o.NotImplementedError(\"convolutions greater than 3D are not implemented yet.\");e=C(t,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(e=this.activation.apply(e))}return e})}computeOutputShape(e){e=(0,u.getExactlyOneShape)(e);const t=[],i=\"channelsLast\"===this.dataFormat?e.slice(1,e.length-1):e.slice(2);for(let n=0;n<i.length;++n){const e=(0,p.convOutputLength)(i[n],this.kernelSize[n],this.padding,this.strides[n],\"number\"==typeof this.dilationRate?this.dilationRate:this.dilationRate[n]);t.push(e)}let r=[e[0]];return\"channelsLast\"===this.dataFormat?(r=r.concat(t)).push(this.filters):(r.push(this.filters),r=r.concat(t)),r}getConfig(){const e={filters:this.filters,kernelInitializer:(0,l.serializeInitializer)(this.kernelInitializer),kernelRegularizer:(0,h.serializeRegularizer)(this.kernelRegularizer),kernelConstraint:(0,s.serializeConstraint)(this.kernelConstraint)},t=super.getConfig();return Object.assign(e,t),e}static verifyArgs(e){if(!(\"filters\"in e)||\"number\"!=typeof e.filters||e.filters<1)throw new o.ValueError(\"Convolution layer expected config.filters to be a 'number' > 0 \"+`but got ${JSON.stringify(e.filters)}`)}}exports.Conv=I;class S extends I{constructor(e){super(2,e),S.verifyArgs(e)}getConfig(){const e=super.getConfig();return delete e.rank,e}static verifyArgs(e){if(\"number\"!=typeof e.kernelSize&&!d.checkArrayTypeAndLength(e.kernelSize,\"number\",1,2))throw new o.ValueError(\"Conv2D expects config.kernelSize to be number or number[] with \"+`length 1 or 2, but received ${JSON.stringify(e.kernelSize)}.`)}}exports.Conv2D=S,S.className=\"Conv2D\",e.serialization.registerClass(S);class R extends I{constructor(e){super(3,e),R.verifyArgs(e)}getConfig(){const e=super.getConfig();return delete e.rank,e}static verifyArgs(e){if(\"number\"!=typeof e.kernelSize&&(!Array.isArray(e.kernelSize)||1!==e.kernelSize.length&&3!==e.kernelSize.length))throw new o.ValueError(\"Conv3D expects config.kernelSize to be number or\"+` [number, number, number], but received ${JSON.stringify(e.kernelSize)}.`)}}exports.Conv3D=R,R.className=\"Conv3D\",e.serialization.registerClass(R);class F extends S{constructor(e){if(super(e),this.inputSpec=[new a.InputSpec({ndim:4})],\"same\"!==this.padding&&\"valid\"!==this.padding)throw new o.ValueError(\"Conv2DTranspose currently supports only padding modes 'same' \"+`and 'valid', but received padding mode ${this.padding}`)}build(e){if(4!==(e=(0,u.getExactlyOneShape)(e)).length)throw new o.ValueError(\"Input should have rank 4; Received input shape: \"+JSON.stringify(e));const t=\"channelsFirst\"===this.dataFormat?1:e.length-1;if(null==e[t])throw new o.ValueError(\"The channel dimension of the inputs should be defined. Found `None`.\");const i=e[t],r=this.kernelSize.concat([this.filters,i]);this.kernel=this.addWeight(\"kernel\",r,\"float32\",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight(\"bias\",[this.filters],\"float32\",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new a.InputSpec({ndim:4,axes:{[t]:i}})],this.built=!0}call(t,i){return e.tidy(()=>{let i=(0,u.getExactlyOneTensor)(t);if(4!==i.shape.length)throw new o.ValueError(\"Conv2DTranspose.call() expects input tensor to be rank-4, but \"+`received a tensor of rank-${i.shape.length}`);const n=i.shape,s=n[0];let a,l;\"channelsFirst\"===this.dataFormat?(a=2,l=3):(a=1,l=2);const h=n[a],d=n[l],c=this.kernelSize[0],g=this.kernelSize[1],f=this.strides[0],m=this.strides[1],z=[s,(0,p.deconvLength)(h,f,c,this.padding),(0,p.deconvLength)(d,m,g,this.padding),this.filters];\"channelsLast\"!==this.dataFormat&&(i=e.transpose(i,[0,2,3,1]));let b=e.conv2dTranspose(i,this.kernel.read(),z,this.strides,this.padding);return\"channelsLast\"!==this.dataFormat&&(b=e.transpose(b,[0,3,1,2])),null!=this.bias&&(b=r.biasAdd(b,this.bias.read(),this.dataFormat)),null!=this.activation&&(b=this.activation.apply(b)),b})}computeOutputShape(e){const t=(e=(0,u.getExactlyOneShape)(e)).slice();let i,r,n;\"channelsFirst\"===this.dataFormat?(i=1,r=2,n=3):(i=3,r=1,n=2);const s=this.kernelSize[0],a=this.kernelSize[1],o=this.strides[0],l=this.strides[1];return t[i]=this.filters,t[r]=(0,p.deconvLength)(t[r],o,s,this.padding),t[n]=(0,p.deconvLength)(t[n],l,a,this.padding),t}getConfig(){const e=super.getConfig();return delete e.dilationRate,e}}exports.Conv2DTranspose=F,F.className=\"Conv2DTranspose\",e.serialization.registerClass(F);class E extends I{constructor(e,t){if(super(e,t),this.DEFAULT_DEPTHWISE_INITIALIZER=\"glorotUniform\",this.DEFAULT_POINTWISE_INITIALIZER=\"glorotUniform\",this.depthwiseKernel=null,this.pointwiseKernel=null,null==t.filters)throw new o.ValueError(\"The `filters` configuration field is required by SeparableConv, but is unspecified.\");if(null!=t.kernelInitializer||null!=t.kernelRegularizer||null!=t.kernelConstraint)throw new o.ValueError(\"Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.\");if(null!=t.padding&&\"same\"!==t.padding&&\"valid\"!==t.padding)throw new o.ValueError(`SeparableConv${this.rank}D supports only padding modes: `+`'same' and 'valid', but received ${JSON.stringify(t.padding)}`);this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=(0,l.getInitializer)(t.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=(0,h.getRegularizer)(t.depthwiseRegularizer),this.depthwiseConstraint=(0,s.getConstraint)(t.depthwiseConstraint),this.pointwiseInitializer=(0,l.getInitializer)(t.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=(0,h.getRegularizer)(t.pointwiseRegularizer),this.pointwiseConstraint=(0,s.getConstraint)(t.pointwiseConstraint)}build(e){if((e=(0,u.getExactlyOneShape)(e)).length<this.rank+2)throw new o.ValueError(`Inputs to SeparableConv${this.rank}D should have rank `+`${this.rank+2}, but received input shape: `+`${JSON.stringify(e)}`);const t=\"channelsFirst\"===this.dataFormat?1:e.length-1;if(null==e[t]||e[t]<0)throw new o.ValueError(\"The channel dimension of the inputs should be defined, \"+`but found ${JSON.stringify(e[t])}`);const i=e[t],r=this.kernelSize.concat([i,this.depthMultiplier]),n=[];for(let s=0;s<this.rank;++s)n.push(1);n.push(i*this.depthMultiplier,this.filters);this.depthwiseKernel=this.addWeight(\"depthwise_kernel\",r,\"float32\",this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight(\"pointwise_kernel\",n,\"float32\",this.pointwiseInitializer,this.pointwiseRegularizer,!0,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight(\"bias\",[this.filters],\"float32\",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.inputSpec=[new a.InputSpec({ndim:this.rank+2,axes:{[t]:i}})],this.built=!0}call(t,i){return(0,e.tidy)(()=>{let i;if(t=(0,u.getExactlyOneTensor)(t),1===this.rank)throw new o.NotImplementedError(\"1D separable convolution is not implemented yet.\");return 2===this.rank&&(\"channelsFirst\"===this.dataFormat&&(t=e.transpose(t,[0,2,3,1])),i=e.separableConv2d(t,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,\"NHWC\")),this.useBias&&(i=r.biasAdd(i,this.bias.read(),this.dataFormat)),null!=this.activation&&(i=this.activation.apply(i)),\"channelsFirst\"===this.dataFormat&&(i=e.transpose(i,[0,3,1,2])),i})}getConfig(){const e=super.getConfig();return delete e.rank,delete e.kernelInitializer,delete e.kernelRegularizer,delete e.kernelConstraint,e.depthwiseInitializer=(0,l.serializeInitializer)(this.depthwiseInitializer),e.pointwiseInitializer=(0,l.serializeInitializer)(this.pointwiseInitializer),e.depthwiseRegularizer=(0,h.serializeRegularizer)(this.depthwiseRegularizer),e.pointwiseRegularizer=(0,h.serializeRegularizer)(this.pointwiseRegularizer),e.depthwiseConstraint=(0,s.serializeConstraint)(this.depthwiseConstraint),e.pointwiseConstraint=(0,s.serializeConstraint)(this.pointwiseConstraint),e}}exports.SeparableConv=E,E.className=\"SeparableConv\";class x extends E{constructor(e){super(2,e)}}exports.SeparableConv2D=x,x.className=\"SeparableConv2D\",e.serialization.registerClass(x);class A extends I{constructor(e){super(1,e),A.verifyArgs(e),this.inputSpec=[{ndim:3}]}getConfig(){const e=super.getConfig();return delete e.rank,delete e.dataFormat,e}static verifyArgs(e){if(\"number\"!=typeof e.kernelSize&&!d.checkArrayTypeAndLength(e.kernelSize,\"number\",1,1))throw new o.ValueError(\"Conv1D expects config.kernelSize to be number or number[] with \"+`length 1, but received ${JSON.stringify(e.kernelSize)}.`)}}exports.Conv1D=A,A.className=\"Conv1D\",e.serialization.registerClass(A);class D extends a.Layer{constructor(e){super(e),\"number\"==typeof e.cropping?this.cropping=[[e.cropping,e.cropping],[e.cropping,e.cropping]]:\"number\"==typeof e.cropping[0]?this.cropping=[[e.cropping[0],e.cropping[0]],[e.cropping[1],e.cropping[1]]]:this.cropping=e.cropping,this.dataFormat=void 0===e.dataFormat?\"channelsLast\":e.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(e){return\"channelsFirst\"===this.dataFormat?[e[0],e[1],e[2]-this.cropping[0][0]-this.cropping[0][1],e[3]-this.cropping[1][0]-this.cropping[1][1]]:[e[0],e[1]-this.cropping[0][0]-this.cropping[0][1],e[2]-this.cropping[1][0]-this.cropping[1][1],e[3]]}call(t,i){return(0,e.tidy)(()=>{if(t=(0,u.getExactlyOneTensor)(t),\"channelsLast\"===this.dataFormat){const e=r.sliceAlongAxis(t,this.cropping[0][0],t.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return r.sliceAlongAxis(e,this.cropping[1][0],t.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const e=r.sliceAlongAxis(t,this.cropping[0][0],t.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return r.sliceAlongAxis(e,this.cropping[1][0],t.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}})}getConfig(){const e={cropping:this.cropping,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}exports.Cropping2D=D,D.className=\"Cropping2D\",e.serialization.registerClass(D);class N extends a.Layer{constructor(e){super(e),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==e.size?this.DEFAULT_SIZE:e.size,this.dataFormat=null==e.dataFormat?\"channelsLast\":e.dataFormat}computeOutputShape(e){if(\"channelsFirst\"===this.dataFormat){const t=null==e[2]?null:this.size[0]*e[2],i=null==e[3]?null:this.size[1]*e[3];return[e[0],e[1],t,i]}{const t=null==e[1]?null:this.size[0]*e[1],i=null==e[2]?null:this.size[1]*e[2];return[e[0],t,i,e[3]]}}call(t,i){return e.tidy(()=>{let i=(0,u.getExactlyOneTensor)(t);const r=i.shape;if(\"channelsFirst\"===this.dataFormat){i=e.transpose(i,[0,2,3,1]);const t=this.size[0]*r[2],n=this.size[1]*r[3],s=i.resizeNearestNeighbor([t,n]);return e.transpose(s,[0,3,1,2])}{const e=this.size[0]*r[1],t=this.size[1]*r[2];return i.resizeNearestNeighbor([e,t])}})}getConfig(){const e={size:this.size,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}exports.UpSampling2D=N,N.className=\"UpSampling2D\",e.serialization.registerClass(N);"},"sourceMaps":null,"error":null,"hash":"c17f658a4b6faaab19cf627621e701f5","cacheData":{"env":{}}}