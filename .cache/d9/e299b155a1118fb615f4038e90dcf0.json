{"id":"C4Cn","dependencies":[{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-data/dist/datasource.js.map","includedInParent":true,"mtime":499162500000},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-data/src/datasource.ts","includedInParent":true,"mtime":499162500000},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/package.json","includedInParent":true,"mtime":1609563562293},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-data/package.json","includedInParent":true,"mtime":499162500000}],"generated":{"js":"\"use strict\";Object.defineProperty(exports,\"__esModule\",{value:!0}),exports.DataSource=void 0;class e{}exports.DataSource=e;"},"sourceMaps":{"js":{"mappings":[{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":0}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":13}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":20}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":35}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":43}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":56}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":57}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":64}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":68}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":76}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":92}},{"source":"../src/datasource.ts","name":null,"original":{"line":28,"column":6},"generated":{"line":1,"column":94}},{"source":"../src/datasource.ts","name":null,"original":{"line":28,"column":22},"generated":{"line":1,"column":100}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":103}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":111}},{"source":"../src/datasource.ts","name":null,"original":{"line":42,"column":0},"generated":{"line":1,"column":122}}],"sources":{"../src/datasource.ts":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {ByteChunkIterator} from './iterators/byte_chunk_iterator';\n\n/**\n * Represents a data source readable as a stream of binary data chunks.\n *\n * Because `Dataset`s can be read repeatedly (via `Dataset.iterator()`), this\n * provides a means to repeatedly create streams from the underlying data\n * sources.\n */\nexport abstract class DataSource {\n  /**\n   * Obtain a new stream of binary data chunks.\n   *\n   * Starts the new stream from the beginning of the data source, even if other\n   * streams have been obtained previously.\n   */\n  abstract async iterator(): Promise<ByteChunkIterator>;\n\n  // TODO(soergel): consider chainable Dataset construction here\n}\n\n// TODO(soergel): consider convenience factory functions here\n// in combination with chainable source->dataset above, e.g.:\n// tf.data.url(...).asCsvDataset().shuffle().batch()\n"},"lineCount":null}},"error":null,"hash":"efc0a2c19ec78c811e8203b9cf122c3a","cacheData":{"env":{}}}