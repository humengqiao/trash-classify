{"id":"efk8","dependencies":[{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js.map","includedInParent":true,"mtime":499162500000},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/src/optimizers/optimizer_constructors.ts","includedInParent":true,"mtime":499162500000},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/package.json","includedInParent":true,"mtime":1609563562293},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/package.json","includedInParent":true,"mtime":499162500000},{"name":"./adadelta_optimizer","loc":{"line":17,"column":34},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js"},{"name":"./adagrad_optimizer","loc":{"line":18,"column":33},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js"},{"name":"./adam_optimizer","loc":{"line":19,"column":30},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js"},{"name":"./adamax_optimizer","loc":{"line":20,"column":32},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js"},{"name":"./momentum_optimizer","loc":{"line":21,"column":34},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js"},{"name":"./rmsprop_optimizer","loc":{"line":22,"column":33},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js"},{"name":"./sgd_optimizer","loc":{"line":23,"column":29},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js"}],"generated":{"js":"\"use strict\";Object.defineProperty(exports,\"__esModule\",{value:!0}),exports.OptimizerConstructors=void 0;var r=require(\"./adadelta_optimizer\"),e=require(\"./adagrad_optimizer\"),t=require(\"./adam_optimizer\"),i=require(\"./adamax_optimizer\"),a=require(\"./momentum_optimizer\"),m=require(\"./rmsprop_optimizer\"),u=require(\"./sgd_optimizer\");class p{static sgd(r){return new u.SGDOptimizer(r)}static momentum(r,e,t=!1){return new a.MomentumOptimizer(r,e,t)}static rmsprop(r,e=.9,t=0,i=null,a=!1){return new m.RMSPropOptimizer(r,e,t,i,a)}static adam(r=.001,e=.9,i=.999,a=null){return new t.AdamOptimizer(r,e,i,a)}static adadelta(e=.001,t=.95,i=null){return new r.AdadeltaOptimizer(e,t,i)}static adamax(r=.002,e=.9,t=.999,a=null,m=0){return new i.AdamaxOptimizer(r,e,t,a,m)}static adagrad(r,t=.1){return new e.AdagradOptimizer(r,t)}}exports.OptimizerConstructors=p;"},"sourceMaps":{"js":{"mappings":[{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":0}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":13}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":20}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":35}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":43}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":56}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":57}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":64}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":68}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":76}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":103}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":18,"column":0},"generated":{"line":1,"column":105}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":18,"column":0},"generated":{"line":1,"column":109}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":18,"column":0},"generated":{"line":1,"column":111}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":18,"column":0},"generated":{"line":1,"column":119}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":19,"column":0},"generated":{"line":1,"column":143}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":19,"column":0},"generated":{"line":1,"column":145}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":19,"column":0},"generated":{"line":1,"column":153}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":20,"column":0},"generated":{"line":1,"column":176}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":20,"column":0},"generated":{"line":1,"column":178}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":20,"column":0},"generated":{"line":1,"column":186}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":21,"column":0},"generated":{"line":1,"column":206}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":21,"column":0},"generated":{"line":1,"column":208}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":21,"column":0},"generated":{"line":1,"column":216}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":22,"column":0},"generated":{"line":1,"column":238}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":22,"column":0},"generated":{"line":1,"column":240}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":22,"column":0},"generated":{"line":1,"column":248}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":23,"column":0},"generated":{"line":1,"column":272}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":23,"column":0},"generated":{"line":1,"column":274}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":23,"column":0},"generated":{"line":1,"column":282}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":24,"column":0},"generated":{"line":1,"column":305}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":24,"column":0},"generated":{"line":1,"column":307}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":24,"column":0},"generated":{"line":1,"column":315}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":6},"generated":{"line":1,"column":334}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":13},"generated":{"line":1,"column":340}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":64,"column":9},"generated":{"line":1,"column":342}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":64,"column":13},"generated":{"line":1,"column":353}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":65,"column":11},"generated":{"line":1,"column":356}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":65,"column":11},"generated":{"line":1,"column":363}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":65,"column":15},"generated":{"line":1,"column":367}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":65,"column":11},"generated":{"line":1,"column":369}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":65,"column":28},"generated":{"line":1,"column":382}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":83,"column":9},"generated":{"line":1,"column":385}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":83,"column":18},"generated":{"line":1,"column":401}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":83,"column":40},"generated":{"line":1,"column":403}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":83,"column":58},"generated":{"line":1,"column":405}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":83,"column":72},"generated":{"line":1,"column":408}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":85,"column":11},"generated":{"line":1,"column":411}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":85,"column":11},"generated":{"line":1,"column":418}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":85,"column":15},"generated":{"line":1,"column":422}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":85,"column":11},"generated":{"line":1,"column":424}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":85,"column":33},"generated":{"line":1,"column":442}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":85,"column":47},"generated":{"line":1,"column":444}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":85,"column":57},"generated":{"line":1,"column":446}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":108,"column":9},"generated":{"line":1,"column":449}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":109,"column":6},"generated":{"line":1,"column":464}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":109,"column":28},"generated":{"line":1,"column":466}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":109,"column":36},"generated":{"line":1,"column":468}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":109,"column":40},"generated":{"line":1,"column":471}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":109,"column":51},"generated":{"line":1,"column":473}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":109,"column":56},"generated":{"line":1,"column":475}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":109,"column":74},"generated":{"line":1,"column":477}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":110,"column":6},"generated":{"line":1,"column":482}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":110,"column":17},"generated":{"line":1,"column":485}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":111,"column":11},"generated":{"line":1,"column":488}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":111,"column":11},"generated":{"line":1,"column":495}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":111,"column":15},"generated":{"line":1,"column":499}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":111,"column":11},"generated":{"line":1,"column":501}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":112,"column":8},"generated":{"line":1,"column":518}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":112,"column":22},"generated":{"line":1,"column":520}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":112,"column":29},"generated":{"line":1,"column":522}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":112,"column":39},"generated":{"line":1,"column":524}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":112,"column":48},"generated":{"line":1,"column":526}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":127,"column":9},"generated":{"line":1,"column":529}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":128,"column":6},"generated":{"line":1,"column":541}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":128,"column":21},"generated":{"line":1,"column":543}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":128,"column":28},"generated":{"line":1,"column":548}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":128,"column":36},"generated":{"line":1,"column":550}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":128,"column":41},"generated":{"line":1,"column":553}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":128,"column":49},"generated":{"line":1,"column":555}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":129,"column":6},"generated":{"line":1,"column":560}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":129,"column":24},"generated":{"line":1,"column":562}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":130,"column":11},"generated":{"line":1,"column":568}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":130,"column":11},"generated":{"line":1,"column":575}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":130,"column":15},"generated":{"line":1,"column":579}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":130,"column":11},"generated":{"line":1,"column":581}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":130,"column":29},"generated":{"line":1,"column":595}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":130,"column":43},"generated":{"line":1,"column":597}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":130,"column":50},"generated":{"line":1,"column":599}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":130,"column":57},"generated":{"line":1,"column":601}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":145,"column":9},"generated":{"line":1,"column":604}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":145,"column":18},"generated":{"line":1,"column":620}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":145,"column":33},"generated":{"line":1,"column":622}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":145,"column":39},"generated":{"line":1,"column":627}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":145,"column":45},"generated":{"line":1,"column":629}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":145,"column":50},"generated":{"line":1,"column":633}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":145,"column":68},"generated":{"line":1,"column":635}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":147,"column":11},"generated":{"line":1,"column":641}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":147,"column":11},"generated":{"line":1,"column":648}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":147,"column":15},"generated":{"line":1,"column":652}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":147,"column":11},"generated":{"line":1,"column":654}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":147,"column":33},"generated":{"line":1,"column":672}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":147,"column":47},"generated":{"line":1,"column":674}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":147,"column":52},"generated":{"line":1,"column":676}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":163,"column":9},"generated":{"line":1,"column":679}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":164,"column":6},"generated":{"line":1,"column":693}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":164,"column":21},"generated":{"line":1,"column":695}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":164,"column":28},"generated":{"line":1,"column":700}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":164,"column":36},"generated":{"line":1,"column":702}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":164,"column":41},"generated":{"line":1,"column":705}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":164,"column":49},"generated":{"line":1,"column":707}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":164,"column":56},"generated":{"line":1,"column":712}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":164,"column":74},"generated":{"line":1,"column":714}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":165,"column":6},"generated":{"line":1,"column":719}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":165,"column":14},"generated":{"line":1,"column":721}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":166,"column":11},"generated":{"line":1,"column":724}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":166,"column":11},"generated":{"line":1,"column":731}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":166,"column":15},"generated":{"line":1,"column":735}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":166,"column":11},"generated":{"line":1,"column":737}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":166,"column":31},"generated":{"line":1,"column":753}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":166,"column":45},"generated":{"line":1,"column":755}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":166,"column":52},"generated":{"line":1,"column":757}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":166,"column":59},"generated":{"line":1,"column":759}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":166,"column":68},"generated":{"line":1,"column":761}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":185,"column":9},"generated":{"line":1,"column":764}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":185,"column":17},"generated":{"line":1,"column":779}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":185,"column":39},"generated":{"line":1,"column":781}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":185,"column":65},"generated":{"line":1,"column":783}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":187,"column":11},"generated":{"line":1,"column":787}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":187,"column":11},"generated":{"line":1,"column":794}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":187,"column":15},"generated":{"line":1,"column":798}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":187,"column":11},"generated":{"line":1,"column":800}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":187,"column":32},"generated":{"line":1,"column":817}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":187,"column":46},"generated":{"line":1,"column":819}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":823}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":831}},{"source":"../../src/optimizers/optimizer_constructors.ts","name":null,"original":{"line":26,"column":34},"generated":{"line":1,"column":853}}],"sources":{"../../src/optimizers/optimizer_constructors.ts":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AdadeltaOptimizer} from './adadelta_optimizer';\nimport {AdagradOptimizer} from './adagrad_optimizer';\nimport {AdamOptimizer} from './adam_optimizer';\nimport {AdamaxOptimizer} from './adamax_optimizer';\nimport {MomentumOptimizer} from './momentum_optimizer';\nimport {RMSPropOptimizer} from './rmsprop_optimizer';\nimport {SGDOptimizer} from './sgd_optimizer';\n\nexport class OptimizerConstructors {\n  /**\n   * Constructs a `tf.SGDOptimizer` that uses stochastic gradient descent.\n   *\n   * ```js\n   * // Fit a quadratic function by learning the coefficients a, b, c.\n   * const xs = tf.tensor1d([0, 1, 2, 3]);\n   * const ys = tf.tensor1d([1.1, 5.9, 16.8, 33.9]);\n   *\n   * const a = tf.scalar(Math.random()).variable();\n   * const b = tf.scalar(Math.random()).variable();\n   * const c = tf.scalar(Math.random()).variable();\n   *\n   * // y = a * x^2 + b * x + c.\n   * const f = x => a.mul(x.square()).add(b.mul(x)).add(c);\n   * const loss = (pred, label) => pred.sub(label).square().mean();\n   *\n   * const learningRate = 0.01;\n   * const optimizer = tf.train.sgd(learningRate);\n   *\n   * // Train the model.\n   * for (let i = 0; i < 10; i++) {\n   *   optimizer.minimize(() => loss(f(xs), ys));\n   * }\n   *\n   * // Make predictions.\n   * console.log(\n   *     `a: ${a.dataSync()}, b: ${b.dataSync()}, c: ${c.dataSync()}`);\n   * const preds = f(xs).dataSync();\n   * preds.forEach((pred, i) => {\n   *   console.log(`x: ${i}, pred: ${pred}`);\n   * });\n   * ```\n   *\n   * @param learningRate The learning rate to use for the SGD algorithm.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static sgd(learningRate: number): SGDOptimizer {\n    return new SGDOptimizer(learningRate);\n  }\n\n  /**\n   * Constructs a `tf.MomentumOptimizer` that uses momentum gradient\n   * descent.\n   *\n   * See\n   * [http://proceedings.mlr.press/v28/sutskever13.pdf](\n   * http://proceedings.mlr.press/v28/sutskever13.pdf)\n   *\n   * @param learningRate The learning rate to use for the Momentum gradient\n   * descent algorithm.\n   * @param momentum The momentum to use for the momentum gradient descent\n   * algorithm.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static momentum(learningRate: number, momentum: number, useNesterov = false):\n      MomentumOptimizer {\n    return new MomentumOptimizer(learningRate, momentum, useNesterov);\n  }\n\n  /**\n   * Constructs a `tf.RMSPropOptimizer` that uses RMSProp gradient\n   * descent. This implementation uses plain momentum and is not centered\n   * version of RMSProp.\n   *\n   * See\n   * [http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf](\n   * http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n   *\n   * @param learningRate The learning rate to use for the RMSProp gradient\n   * descent algorithm.\n   * @param decay The discounting factor for the history/coming gradient.\n   * @param momentum The momentum to use for the RMSProp gradient descent\n   * algorithm.\n   * @param epsilon Small value to avoid zero denominator.\n   * @param centered If true, gradients are normalized by the estimated\n   * variance of the gradient.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static rmsprop(\n      learningRate: number, decay = .9, momentum = 0.0, epsilon: number = null,\n      centered = false): RMSPropOptimizer {\n    return new RMSPropOptimizer(\n        learningRate, decay, momentum, epsilon, centered);\n  }\n\n  /**\n   * Constructs a `tf.AdamOptimizer` that uses the Adam algorithm.\n   * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)\n   *\n   * @param learningRate The learning rate to use for the Adam gradient\n   * descent algorithm.\n   * @param beta1 The exponential decay rate for the 1st moment estimates.\n   * @param beta2 The exponential decay rate for the 2nd moment estimates.\n   * @param epsilon A small constant for numerical stability.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static adam(\n      learningRate = 0.001, beta1 = 0.9, beta2 = 0.999,\n      epsilon: number = null): AdamOptimizer {\n    return new AdamOptimizer(learningRate, beta1, beta2, epsilon);\n  }\n\n  /**\n   * Constructs a `tf.AdadeltaOptimizer` that uses the Adadelta algorithm.\n   * See [https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701)\n   *\n   * @param learningRate The learning rate to use for the Adadelta gradient\n   * descent algorithm.\n   * @param rho The learning rate decay over each update.\n   * @param epsilon A constant epsilon used to better condition the grad\n   * update.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static adadelta(learningRate = .001, rho = .95, epsilon: number = null):\n      AdadeltaOptimizer {\n    return new AdadeltaOptimizer(learningRate, rho, epsilon);\n  }\n\n  /**\n   * Constructs a `tf.AdamaxOptimizer` that uses the Adamax algorithm.\n   * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)\n   *\n   * @param learningRate The learning rate to use for the Adamax gradient\n   * descent algorithm.\n   * @param beta1 The exponential decay rate for the 1st moment estimates.\n   * @param beta2 The exponential decay rate for the 2nd moment estimates.\n   * @param epsilon A small constant for numerical stability.\n   * @param decay The learning rate decay over each update.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static adamax(\n      learningRate = 0.002, beta1 = 0.9, beta2 = 0.999, epsilon: number = null,\n      decay = 0.0): AdamaxOptimizer {\n    return new AdamaxOptimizer(learningRate, beta1, beta2, epsilon, decay);\n  }\n\n  /**\n   * Constructs a `tf.AdagradOptimizer` that uses the Adagrad algorithm.\n   * See\n   * [http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf](\n   * http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n   * or\n   * [http://ruder.io/optimizing-gradient-descent/index.html#adagrad](\n   * http://ruder.io/optimizing-gradient-descent/index.html#adagrad)\n   *\n   * @param learningRate The learning rate to use for the Adagrad gradient\n   * descent algorithm.\n   * @param initialAccumulatorValue Starting value for the accumulators, must be\n   * positive.\n   *\n   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n   */\n  static adagrad(learningRate: number, initialAccumulatorValue = 0.1):\n      AdagradOptimizer {\n    return new AdagradOptimizer(learningRate, initialAccumulatorValue);\n  }\n}\n"},"lineCount":null}},"error":null,"hash":"c58d8bf851a8e801b93d03d14e9e8a0e","cacheData":{"env":{}}}