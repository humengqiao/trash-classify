{"id":"QFjJ","dependencies":[{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/package.json","includedInParent":true,"mtime":1609564004117},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":499162500000},{"name":"@tensorflow/tfjs-core","loc":{"line":11,"column":21},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/index.js"},{"name":"../backend/state","loc":{"line":12,"column":23},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/backend/state.js"},{"name":"../errors","loc":{"line":13,"column":62},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/errors.js"},{"name":"../layers/serialization","loc":{"line":14,"column":48},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/serialization.js"},{"name":"../utils/generic_utils","loc":{"line":15,"column":31},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/generic_utils.js"},{"name":"../utils/serialization_utils","loc":{"line":16,"column":36},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/serialization_utils.js"},{"name":"../utils/types_utils","loc":{"line":17,"column":29},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/types_utils.js"},{"name":"../variables","loc":{"line":18,"column":30},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/variables.js"},{"name":"../version","loc":{"line":19,"column":41},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/version.js"},{"name":"./executor","loc":{"line":20,"column":34},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/executor.js"},{"name":"./input_layer","loc":{"line":21,"column":27},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/input_layer.js"},{"name":"./topology","loc":{"line":22,"column":28},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/container.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js"}],"generated":{"js":"\"use strict\";Object.defineProperty(exports,\"__esModule\",{value:!0}),exports.Container=void 0;var t=require(\"@tensorflow/tfjs-core\"),e=require(\"../backend/state\"),s=require(\"../errors\"),n=require(\"../layers/serialization\"),o=d(require(\"../utils/generic_utils\")),i=require(\"../utils/serialization_utils\"),r=d(require(\"../utils/types_utils\")),a=require(\"../variables\"),u=require(\"../version\"),l=require(\"./executor\"),h=require(\"./input_layer\"),p=require(\"./topology\");function c(){if(\"function\"!=typeof WeakMap)return null;var t=new WeakMap;return c=function(){return t},t}function d(t){if(t&&t.__esModule)return t;if(null===t||\"object\"!=typeof t&&\"function\"!=typeof t)return{default:t};var e=c();if(e&&e.has(t))return e.get(t);var s={},n=Object.defineProperty&&Object.getOwnPropertyDescriptor;for(var o in t)if(Object.prototype.hasOwnProperty.call(t,o)){var i=n?Object.getOwnPropertyDescriptor(t,o):null;i&&(i.get||i.set)?Object.defineProperty(s,o,i):s[o]=t[o]}return s.default=t,e&&e.set(t,s),s}class f extends p.Layer{constructor(t){if(super({}),this.containerNodes=new Set,this.name=t.name,null==this.name){const t=this.getClassName().toLowerCase();this.name=(0,e.getUid)(t)}if(this.supportsMasking=!1,this.trainable_=!0,Array.isArray(t.inputs)?this.inputs=t.inputs.slice():this.inputs=[t.inputs],Array.isArray(t.outputs)?this.outputs=t.outputs.slice():this.outputs=[t.outputs],o.unique(this.inputs).length!==this.inputs.length)throw new s.ValueError(\"The list of inputs passed to the model is redundant. All inputs should only appear once. Found: \"+`${this.inputs.map(t=>t.name)}`);o.unique(this.outputs).length!==this.outputs.length&&console.warn(\"The list of outputs passed to the model is redundant. All outputs should only appear once. Found: \"+`${this.outputs.map(t=>t.name)}`),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const e of this.outputs){const t=e.sourceLayer,s=e.nodeIndex,n=e.tensorIndex;this.outputLayers.push(t),this.outputLayersNodeIndices.push(s),this.outputLayersTensorIndices.push(n)}for(const e of this.inputs){const t=e.sourceLayer,s=e.nodeIndex,n=e.tensorIndex;o.assert(0===s,\"input layer has >1 nodes\"),o.assert(0===n,\"input layer has >1 tensors\"),this.inputLayers.push(t),this.inputLayersNodeIndices.push(s),this.inputLayersTensorIndices.push(n)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let e=0;e<this.inputLayers.length;e++){const s=this.inputLayers[e];if(!(s instanceof h.InputLayer))throw new TypeError(\"Input layers to a LayersModel must be InputLayer objects. \"+`Received inputs: ${t.inputs}. `+`Input ${e} (0-based) originates `+`from layer type ${s.getClassName()}.`);this.inputNames.push(s.name),this.feedInputShapes.push(s.batchInputShape),this.feedInputNames.push(s.name)}for(const e of this.outputLayers)this.outputNames.push(e.name);this.internalInputShapes=this.inputs.map(t=>t.shape),this.internalOutputShapes=this.outputs.map(t=>t.shape);const n={},i={},r={},a={},u={},l=[],c=(t,e,n,o,i,r)=>{null!=o&&null!=i&&null!=r||(o=t.sourceLayer,i=t.nodeIndex,r=t.tensorIndex);const a=o.inboundNodes[i];if(-1!==n.indexOf(a))throw new s.RuntimeError(`The tensor ${t.name} at layer \"${o.name}\" `+\"is part of a cycle.\");if(-1!==e.indexOf(a))return;this.containerNodes.add(f.nodeKey(o,i)),o.id in u||(u[o.id]=Object.keys(u).length),-1===n.indexOf(a)&&n.push(a);const h=a.inboundLayers.length;for(let s=0;s<h;s++){const t=a.inputTensors[s],o=a.inboundLayers[s],i=a.nodeIndices[s],r=a.tensorIndices[s];c(t,e,n,o,i,r)}for(e.push(a);n.indexOf(a)>=0;)n.splice(n.indexOf(a),1);l.push(a)},d=[],y=[];for(const e of this.outputs)c(e,d,y);const m=l.slice().reverse();for(const e of m){i[e.id]=e,e.id in n||(n[e.id]=0);let t=n[e.id];const s=null==r[e.outboundLayer.id]?0:r[e.outboundLayer.id];t=Math.max(t,s),r[e.outboundLayer.id]=t,a[e.outboundLayer.id]=e.outboundLayer,n[e.id]=t;for(let o=0;o<e.inboundLayers.length;o++){const s=e.inboundLayers[o],r=e.nodeIndices[o],a=s.inboundNodes[r],u=null==n[a.id]?0:n[a.id];n[a.id]=Math.max(t+1,u),i[a.id]=a}}const g={};for(const e in n){const t=n[e];t in g||(g[t]=[]),g[t].push(i[e])}const b={};for(const e in r){const t=r[e];t in b||(b[t]=[]),b[t].push(a[e])}let L=Object.keys(b).map(t=>parseInt(t,10)).sort(o.reverseNumberCompare);this.layers=[];for(const e of L){const t=b[e];t.sort((t,e)=>{const s=u[t.id],n=u[e.id];return s<n?-1:s>n?1:0});for(const e of t)e instanceof f&&this.internalContainerRefs.push(e),this.layers.push(e)}this.layersByDepth=b,L=Object.keys(g).map(t=>parseInt(t,10)).sort(o.reverseNumberCompare);const w=this.inputs.slice(),N=[];for(const e of L)for(const t of g[e]){const e=t.outboundLayer;if(null!=e){for(const n of t.inputTensors)if(-1===w.indexOf(n))throw new s.RuntimeError(`Graph disconnected: cannot obtain value for tensor ${n}`+` at layer \"${e.name}\". `+\"The following previous layers were accessed without \"+`issue: ${N}`);for(const e of t.outputTensors)w.push(e);N.push(e.name)}}this.nodesByDepth=g;const I=this.layers.map(t=>t.name);for(const e of I){const t=I.filter(t=>t===e).length;if(1!==t)throw new s.RuntimeError(`The name \"${e}\" is used ${t} times `+\"in the model. All layer names should be unique. Layer names: \"+JSON.stringify(I))}this.outboundNodes=[],this.inboundNodes=[],new p.Node({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map(t=>null),outputMasks:this.outputs.map(t=>null),inputShapes:this.inputs.map(t=>t.shape),outputShapes:this.outputs.map(t=>t.shape)}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const t={refCountAfterDispose:null,numDisposedVariables:0};if(0==--this._refCount){for(const e of this.layers)t.numDisposedVariables+=e.dispose().numDisposedVariables;for(const e of this.internalContainerRefs)t.numDisposedVariables+=e.dispose().numDisposedVariables}return t.refCountAfterDispose=this._refCount,t}get trainable(){return this.trainable_}set trainable(t){this.layers.forEach(e=>{e._trainableWeights.forEach(e=>e.trainable=t)}),this.trainable_=t}get trainableWeights(){if(this._trainableWeights.length>0)throw new s.ValueError(\"Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.\");if(!this.trainable)return[];let t=[];for(const e of this.layers)t=t.concat(e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.layers)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.layers)e.push(...t.trainableWeights);return e.concat(t)}return t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(t,e=!0){const n={};let o=0;for(const r of this.layers)for(const t of r.weights){if(null!=n[t.originalName])throw new s.ValueError(`Duplicate weight name: ${t.originalName}`);n[t.originalName]=t,o++}const i=[];for(const r in t){let o=r;if(null==n[r]){const t=r.split(\"/\");o=t.slice(0,-2).concat([t[t.length-1]]).join(\"/\")}if(null!=n[o])i.push([n[o],t[r]]);else if(e)throw new s.ValueError(`Provided weight data has no target variable: ${r}`);delete n[o]}if(e){const t=[];for(const e in n)t.push(e);if(t.length>0)throw new s.ValueError(`${t.length} of ${o} weights are not set: `+`${t}`)}(0,a.batchSetValue)(i)}updatedConfig(){const t=this.getConfig(),e={};return e.className=this.getClassName(),e.config=t,e.kerasVersion=`tfjs-layers ${u.version}`,e.backend=\"TensorFlow.js\",e}toJSON(t,e=!0){const s=(0,i.convertTsToPythonic)(this.updatedConfig());return e?JSON.stringify(s):s}call(e,s){return(0,t.tidy)(()=>{e=o.toList(e);const t=new l.FeedDict;for(let s=0;s<this.inputs.length;++s)t.add(this.inputs[s],e[s]);return(0,l.execute)(this.outputs,t,s)})}computeMask(e,s){return(0,t.tidy)(()=>{let t;return e=o.toList(e),t=null==s?o.pyListRepeat(null,e.length):o.toList(s),this.runInternalGraph(e,t)[1]})}computeOutputShape(t){const e=r.normalizeShapeList(t);if(e.length!==this.inputLayers.length)throw new s.ValueError(`Invalid inputShape argument ${t}: `+`model has ${this.inputLayers.length} tensor inputs.`);const n={};for(let s=0;s<e.length;s++){const t=this.inputLayers[s],o=e[s];n[t.name+\"_0_0\"]=o}const i=Object.keys(this.nodesByDepth).map(t=>parseInt(t,10)).sort(o.reverseNumberCompare);if(i.length>1)for(const s of i){const t=this.nodesByDepth[s];for(const e of t){const t=e.outboundLayer;if(-1!==this.inputLayers.map(t=>t.id).indexOf(t.id))continue;const s=[];for(let o=0;o<e.inboundLayers.length;o++){const t=e.inboundLayers[o],i=e.nodeIndices[o],r=e.tensorIndices[o],a=n[`${t.name}_${i}_${r}`];s.push(a)}const i=t.computeOutputShape(o.singletonOrArray(s)),a=r.normalizeShapeList(i),u=t.inboundNodes.indexOf(e);for(let e=0;e<a.length;e++){n[`${t.name}_${u}_${e}`]=a[e]}}}const a=[],u=[];for(let s=0;s<this.outputLayers.length;s++){const t=this.outputLayers[s],e=this.outputLayersNodeIndices[s],n=this.outputLayersTensorIndices[s],o=`${t.name}_${e}_${n}`;u.push(o)}for(let s=0;s<u.length;s++){const t=u[s];o.assert(t in n),a.push(n[t])}return o.singletonOrArray(a)}runInternalGraph(t,e){null==e&&(e=o.pyListRepeat(null,t.length));const n={};for(let s=0;s<this.inputs.length;++s){const o=this.inputs[s],i=t[s],r=e[s];n[o.id]=[i,r]}const i=Object.keys(this.nodesByDepth).map(t=>parseInt(t,10)).sort(o.reverseNumberCompare);for(const l of i){const t=this.nodesByDepth[l];for(const e of t){const t=e.outboundLayer,i=e.inputTensors,r=e.outputTensors,a=new Array;for(const e of i)e.id in n&&a.push(n[e.id]);if(a.length===i.length){let i,u,l,h,p={};if(null!=e.callArgs&&(p=e.callArgs),1===a.length){const[e,s]=a[0];null==p.mask&&(p.mask=s),l=o.toList(t.call(e,p)),h=o.toList(t.computeMask(e,s)),i=[e],u=[s]}else i=a.map(t=>t[0]),u=a.map(t=>t[1]),null==p.mask&&(p.mask=u),l=o.toList(t.call(i,p)),h=o.toList(t.computeMask(i,u));if(t.activityRegularizer)throw new s.NotImplementedError(\"LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.\");for(let t=0;t<r.length;++t){const e=r[t],s=l[t],o=h[t];n[e.id]=[s,o]}}}}const r=[],a=[],u=[];for(const s of this.outputs){o.assert(s.id in n,`Could not compute output ${s.name} : ${s.id}`);const[t,e]=n[s.id];u.push(t.shape),r.push(t),a.push(e)}return[r,a,u]}buildNodeConversionMap(t){const e={};let s;for(const n of this.layers){s=n instanceof f?1:0;for(let t=0;t<n.inboundNodes.length;t++){const o=f.nodeKey(n,t);this.containerNodes.has(o)&&(e[o]=s,s+=1)}}return e}getLayer(t,e){if(null!=e){if(this.layers.length<=e)throw new s.ValueError(`Was asked to retrieve layer at index ${e}, but model only `+`has ${this.layers.length} layer(s).`);return this.layers[e]}if(null==t)throw new s.ValueError(\"Provide either a layer name or layer index\");for(const s of this.layers)if(s.name===t)return s;throw new s.ValueError(`No such layer: ${t}`)}calculateLosses(){return(0,t.tidy)(()=>{const t=[];for(const e of this.layers)for(let s=0;s<e.inboundNodes.length;++s){const n=f.nodeKey(e,s);this.containerNodes.has(n)&&t.push(...e.calculateLosses())}return t})}getConfig(){const t={name:this.name},e=this.buildNodeConversionMap(this.layers),s=[];for(const r of this.layers){const t=r.getClassName(),n=r.getConfig(),o=[];for(let s=0;s<r.inboundNodes.length;s++){const t=r.inboundNodes[s],n=f.nodeKey(r,s);let a={};if(this.containerNodes.has(n)){if(t.callArgs)try{JSON.stringify(t.callArgs),a=t.callArgs}catch(i){console.warn(`Layer ${r.name} was passed `+\"non-serializable keyword arguments: \"+`${t.callArgs}. They will not be included `+\"in the serialized model (and thus will be missing at deserialization time).\"),a={}}if(t.inboundLayers.length>0){const s=[];for(let n=0;n<t.inboundLayers.length;n++){const o=t.inboundLayers[n],i=t.nodeIndices[n],r=t.tensorIndices[n];let u=e[f.nodeKey(o,i)];null==u&&(u=0),s.push([o.name,u,r,a])}o.push(s)}}}const a={};a.name=r.name,a.className=t,a.config=n,a.inboundNodes=o,s.push(a)}t.layers=s;const n=[];for(let r=0;r<this.inputLayers.length;r++){const t=this.inputLayers[r],s=this.inputLayersNodeIndices[r],o=f.nodeKey(t,s);if(!this.containerNodes.has(o))continue;let i=e[o];null==i&&(i=0);const a=this.inputLayersTensorIndices[r];n.push([t.name,i,a])}t.inputLayers=n;const o=[];for(let r=0;r<this.outputLayers.length;r++){const t=this.outputLayers[r],s=this.outputLayersNodeIndices[r],n=f.nodeKey(t,s);if(!this.containerNodes.has(n))continue;let i=e[n];null==i&&(i=0);const a=this.outputLayersTensorIndices[r];o.push([t.name,i,a])}return t.outputLayers=o,t}static fromConfig(t,e,i={},r=!1){const a={},u={};function l(t,e){t.name in u?u[t.name].push(e):u[t.name]=[e]}function h(t,e){const s=[];let n;for(const o of e){const i=o[0],r=o[1],u=o[2];if(n=null==o[3]?{}:o[3],!(i in a))return void l(t,e);const h=a[i];if(h.inboundNodes.length<=r)return void l(t,e);const p=h.inboundNodes[r];s.push(p.outputTensors[u])}s.length>0&&t.apply(o.singletonOrArray(s),n)}function p(t){const o=t.name,i=(0,n.deserialize)(t,null!=e.customObjects?e.customObjects:{});i.setFastWeightInitDuringBuild(r),a[o]=i,t.inboundNodes.forEach(t=>{if(!(t instanceof Array))throw new s.ValueError(`Corrupted configuration, expected array for nodeData: ${t}`);l(i,t)})}const c=e.name,d=e.layers;for(const s of d)p(s);for(;!o.isObjectEmpty(u);)for(const t of d){const e=a[t.name];if(e.name in u){const t=u[e.name];delete u[e.name];for(const s of t)h(e,s)}}const f=[],y=[],m=e.inputLayers;for(const s of m){const t=s[0],e=s[1],n=s[2];o.assert(t in a);const i=a[t].inboundNodes[e].outputTensors;f.push(i[n])}const g=e.outputLayers;for(const s of g){const t=s[0],e=s[1],n=s[2];o.assert(t in a);const i=a[t].inboundNodes[e].outputTensors;y.push(i[n])}return new t({inputs:f,outputs:y,name:c})}get stateful(){if(this._stateful)throw new s.ValueError(\"Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.\");for(const t of this.layers)if(t.stateful)return!0;return!1}resetStates(){(0,t.tidy)(()=>{this.layers.forEach(t=>{t.stateful&&t.resetStates()})})}}exports.Container=f;"},"sourceMaps":null,"error":null,"hash":"862f041bac2465d502b636284bfd2997","cacheData":{"env":{}}}