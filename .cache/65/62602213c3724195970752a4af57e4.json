{"id":"Ht5L","dependencies":[{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/package.json","includedInParent":true,"mtime":1609564004117},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-converter/package.json","includedInParent":true,"mtime":499162500000},{"name":"@tensorflow/tfjs-core","loc":{"line":17,"column":83},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_array.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/index.js"},{"name":"./tensor_utils","loc":{"line":18,"column":52},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_array.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_utils.js"}],"generated":{"js":"\"use strict\";Object.defineProperty(exports,\"__esModule\",{value:!0}),exports.TensorArray=void 0;var e=require(\"@tensorflow/tfjs-core\"),t=require(\"./tensor_utils\");class s{constructor(t,s,r,i,n,a,h){this.name=t,this.dtype=s,this.maxSize=r,this.elementShape=i,this.identicalElementShapes=n,this.dynamicSize=a,this.clearAfterRead=h,this.tensors=[],this.closed_=!1,this.idTensor=(0,e.scalar)(0),(0,e.keep)(this.idTensor)}get id(){return this.idTensor.id}get closed(){return this.closed_}clearAndClose(e){this.tensors.forEach(t=>{null!=e&&e.has(t.tensor.id)||t.tensor.dispose()}),this.tensors=[],this.closed_=!0,this.idTensor.dispose()}size(){return this.tensors.length}read(e){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(e<0||e>=this.size())throw new Error(`Tried to read from index ${e}, but array size is: ${this.size()}`);const t=this.tensors[e];if(t.cleared)throw new Error(`TensorArray ${this.name}: Could not read index ${e} twice because it was cleared after a previous read `+\"(perhaps try setting clear_after_read = false?).\");return this.clearAfterRead&&(t.cleared=!0),t.read=!0,t.tensor}readMany(e){return e.map(e=>this.read(e))}write(s,r){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(s<0||!this.dynamicSize&&s>=this.maxSize)throw new Error(`Tried to write to index ${s}, but array is not resizeable and size is: ${this.maxSize}`);const i=this.tensors[s]||{};if(r.dtype!==this.dtype)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${s},\\n          because the value dtype is ${r.dtype}, but TensorArray dtype is ${this.dtype}.`);if(0!==this.size()||null!=this.elementShape&&0!==this.elementShape.length||(this.elementShape=r.shape),(0,t.assertShapesMatchAllowUndefinedSize)(this.elementShape,r.shape,`TensorArray ${this.name}: Could not write to TensorArray index ${s}.`),i.read)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${s}, because it has already been read.`);if(i.written)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${s}, because it has already been written.`);i.tensor=r,(0,e.keep)(r),i.written=!0,this.tensors[s]=i}writeMany(e,t){if(e.length!==t.length)throw new Error(`TensorArray ${this.name}: could not write multiple tensors,`+`because the index size: ${e.length} is not the same as tensors size: ${t.length}.`);e.forEach((e,s)=>this.write(e,t[s]))}gather(s,r){if(r&&r!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${r}`);if(s)s=s.slice(0,this.size());else{s=[];for(let e=0;e<this.size();e++)s.push(e)}if(0===s.length)return(0,e.tensor)([],[0].concat(this.elementShape));const i=this.readMany(s);return(0,t.assertShapesMatchAllowUndefinedSize)(this.elementShape,i[0].shape,\"TensorArray shape mismatch: \"),(0,e.stack)(i,0)}concat(s){if(s&&s!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${s}`);if(0===this.size())return(0,e.tensor)([],[0].concat(this.elementShape));const r=[];for(let e=0;e<this.size();e++)r.push(e);const i=this.readMany(r);return(0,t.assertShapesMatchAllowUndefinedSize)(this.elementShape,i[0].shape,`TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${i[0].shape})`),(0,e.concat)(i,0)}scatter(t,s){if(s.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${s.dtype}`);if(t.length!==s.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${t.length} vs. ${s.shape[0]}`);const r=Math.max(...t);if(!this.dynamicSize&&r>=this.maxSize)throw new Error(`Max index must be < array size (${r}  vs. ${this.maxSize})`);this.writeMany(t,(0,e.unstack)(s,0))}split(t,s){if(s.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${s.dtype}`);let r=0;const i=t.map(e=>r+=e);if(r!==s.shape[0])throw new Error(`Expected sum of lengths to be equal to\\n          tensor.shape[0], but sum of lengths is\\n        ${r}, and tensor's shape is: ${s.shape}`);if(!this.dynamicSize&&t.length!==this.maxSize)throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${t.length}), `+\"and the TensorArray is not marked as dynamically resizeable\");const n=0===r?0:s.size/r,a=[];(0,e.tidy)(()=>{s=(0,e.reshape)(s,[1,r,n]);for(let r=0;r<t.length;++r){const h=[0,0===r?0:i[r-1],0],o=[1,t[r],n];a[r]=(0,e.reshape)((0,e.slice)(s,h,o),this.elementShape)}return a});const h=[];for(let e=0;e<t.length;e++)h[e]=e;this.writeMany(h,a)}}exports.TensorArray=s;"},"sourceMaps":null,"error":null,"hash":"dca99f1e76e5c509999e1d265c8b5176","cacheData":{"env":{}}}