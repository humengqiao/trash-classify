{"id":"wHpB","dependencies":[{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/package.json","includedInParent":true,"mtime":1609565602436},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":499162500000},{"name":"@tensorflow/tfjs-core","loc":{"line":11,"column":42},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/index.js"},{"name":"../backend/state","loc":{"line":12,"column":46},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/backend/state.js"},{"name":"../common","loc":{"line":13,"column":68},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/common.js"},{"name":"../errors","loc":{"line":14,"column":78},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/errors.js"},{"name":"../initializers","loc":{"line":15,"column":31},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/initializers.js"},{"name":"../utils/generic_utils","loc":{"line":16,"column":31},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/generic_utils.js"},{"name":"../utils/types_utils","loc":{"line":17,"column":29},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/types_utils.js"},{"name":"../utils/variable_utils","loc":{"line":18,"column":32},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/variable_utils.js"},{"name":"../variables","loc":{"line":19,"column":60},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/variables.js"}],"generated":{"js":"\"use strict\";Object.defineProperty(exports,\"__esModule\",{value:!0}),exports.getSourceInputs=w,exports.Layer=exports.Node=exports.SymbolicTensor=exports.InputSpec=void 0;var t=require(\"@tensorflow/tfjs-core\"),e=require(\"../backend/state\"),n=require(\"../common\"),i=require(\"../errors\"),s=require(\"../initializers\"),r=l(require(\"../utils/generic_utils\")),o=l(require(\"../utils/types_utils\")),a=l(require(\"../utils/variable_utils\")),h=require(\"../variables\");function u(){if(\"function\"!=typeof WeakMap)return null;var t=new WeakMap;return u=function(){return t},t}function l(t){if(t&&t.__esModule)return t;if(null===t||\"object\"!=typeof t&&\"function\"!=typeof t)return{default:t};var e=u();if(e&&e.has(t))return e.get(t);var n={},i=Object.defineProperty&&Object.getOwnPropertyDescriptor;for(var s in t)if(Object.prototype.hasOwnProperty.call(t,s)){var r=i?Object.getOwnPropertyDescriptor(t,s):null;r&&(r.get||r.set)?Object.defineProperty(n,s,r):n[s]=t[s]}return n.default=t,e&&e.set(t,n),n}class p{constructor(t){this.dtype=t.dtype,this.shape=t.shape,null!=t.shape?this.ndim=t.shape.length:this.ndim=t.ndim,this.maxNDim=t.maxNDim,this.minNDim=t.minNDim,this.axes=t.axes||{}}}exports.InputSpec=p;class d{constructor(t,i,s,r,o,a,h){this.dtype=t,this.shape=i,this.sourceLayer=s,this.inputs=r,this.callArgs=o,this.outputTensorIndex=h,this.id=(0,e.getNextUniqueTensorId)(),null!=a&&(this.originalName=(0,n.getScopedTensorName)(a),this.name=(0,n.getUniqueTensorName)(this.originalName)),this.rank=i.length}}exports.SymbolicTensor=d;let c=0;class f{constructor(t,e){this.callArgs=e,this.id=c++,this.outboundLayer=t.outboundLayer,this.inboundLayers=t.inboundLayers,this.nodeIndices=t.nodeIndices,this.tensorIndices=t.tensorIndices,this.inputTensors=t.inputTensors,this.outputTensors=t.outputTensors,this.inputMasks=t.inputMasks,this.outputMasks=t.outputMasks,this.inputShapes=t.inputShapes,this.outputShapes=t.outputShapes;for(const n of t.inboundLayers)null!=n&&n.outboundNodes.push(this);t.outboundLayer.inboundNodes.push(this)}getConfig(){const t=[];for(const e of this.inboundLayers)null!=e?t.push(e.name):t.push(null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:t,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}exports.Node=f;let b=0;class g extends t.serialization.Serializable{constructor(t={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=b++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let n=t.name;if(!n){const t=this.getClassName();n=r.toSnakeCase(t)+\"_\"+(0,e.getUid)(t)}if(this.name=n,this.trainable_=null==t.trainable||t.trainable,null!=t.inputShape||null!=t.batchInputShape){let e;if(null!=t.batchInputShape)e=t.batchInputShape;else if(null!=t.inputShape){let n=null;null!=t.batchSize&&(n=t.batchSize),e=[n].concat(t.inputShape)}this.batchInputShape=e;let n=t.dtype;null==n&&(n=t.inputDType),null==n&&(n=\"float32\"),this.dtype=n}null!=t.weights?this.initialWeights=t.weights:this.initialWeights=null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(t,e){return t.name+\"_ib-\"+e.toString()}getNodeAtIndex(t,e){if(0===this.inboundNodes.length)throw new i.RuntimeError(\"The layer has never been called \"+`and thus has no defined ${e}.`);if(this.inboundNodes.length<=t)throw new i.ValueError(`Asked to get ${e} at node ${t}, `+`but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[t]}getInputAt(t){return r.singletonOrArray(this.getNodeAtIndex(t,\"input\").inputTensors)}getOutputAt(t){return r.singletonOrArray(this.getNodeAtIndex(t,\"output\").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new i.AttributeError(`Layer ${this.name}`+' has multiple inbound nodes, hence the notion of \"layer input\" is ill-defined. Use `getInputAt(nodeIndex)` instead.');if(0===this.inboundNodes.length)throw new i.AttributeError(`Layer ${this.name}`+\" is not connected, no input to return.\");return r.singletonOrArray(this.getNodeAtIndex(0,\"input\").inputTensors)}get output(){if(0===this.inboundNodes.length)throw new i.AttributeError(`Layer ${this.name}`+\" has no inbound nodes.\");if(this.inboundNodes.length>1)throw new i.AttributeError(`Layer ${this.name}`+' has multiple inbound nodes, hence the notion of \"layer output\" is ill-defined. Use `getOutputAt(nodeIndex)` instead.');return r.singletonOrArray(this.getNodeAtIndex(0,\"output\").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map(t=>t())}get updates(){return this._updates}get built(){return this._built}set built(t){this._built=t}get trainable(){return this.trainable_}set trainable(t){this._trainableWeights.forEach(e=>e.trainable=t),this.trainable_=t}get trainableWeights(){return this.trainable_?this._trainableWeights.filter(t=>t.trainable):[]}set trainableWeights(t){this._trainableWeights=t}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter(t=>!t.trainable).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(t){this._nonTrainableWeights=t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error(\"Cannot call the resetStates() method of a non-stateful Layer object.\")}assertInputCompatibility(t){if(t=r.toList(t),null==this.inputSpec||0===this.inputSpec.length)return;const e=r.toList(this.inputSpec);if(t.length!==e.length)throw new i.ValueError(`Layer ${this.name} expects ${e.length} inputs, `+`but it received ${t.length} input tensors. `+`Input received: ${t}`);for(let n=0;n<t.length;n++){const s=t[n],r=e[n];if(null==r)continue;const o=s.rank;if(null!=r.ndim&&o!==r.ndim)throw new i.ValueError(`Input ${n} is incompatible with layer ${this.name}: `+`expected ndim=${r.ndim}, found ndim=${o}`);if(null!=r.maxNDim&&o>r.maxNDim)throw new i.ValueError(`Input ${n} is incompatible with layer ${this.name}`+`: expected max_ndim=${r.maxNDim}, found ndim=${o}`);if(null!=r.minNDim&&o<r.minNDim)throw new i.ValueError(`Input ${n} is incompatible with layer ${this.name}`+`: expected min_ndim=${r.minNDim}, found ndim=${o}.`);if(null!=r.dtype&&s.dtype!==r.dtype)throw new i.ValueError(`Input ${n} is incompatible with layer ${this.name} `+`: expected dtype=${r.dtype}, found dtype=${s.dtype}.`);if(r.axes){const t=s.shape;for(const e in r.axes){const s=Number(e),o=r.axes[e],a=s>=0?t[s]:t[t.length+s];if(null!=o&&-1===[o,null].indexOf(a))throw new i.ValueError(`Input ${n} is incompatible with layer `+`${this.name}: expected axis ${s} of input shape to `+`have value ${o} but got shape ${t}.`)}}if(null!=r.shape)for(let t=0;t<r.shape.length;++t){const e=r.shape[t],o=s.shape[t];if(null!=e&&null!=o&&e!==o)throw new i.ValueError(`Input ${n} is incompatible with layer `+`${this.name}: expected shape=${r.shape}, `+`found shape=${s.shape}.`)}}}call(t,e){return t}invokeCallHook(t,e){null!=this._callHook&&this._callHook(t,e)}setCallHook(t){this._callHook=t}clearCallHook(){this._callHook=null}apply(t,e){e=e||{},this.assertNotDisposed();const s=r.toList(t);let o=!0;for(const n of s)if(!(n instanceof d)){o=!1;break}let a=!0;for(const n of s)if(n instanceof d){a=!1;break}if(o===a)throw new i.ValueError(\"Arguments to apply() must be all SymbolicTensors or all Tensors\");return(0,n.nameScope)(this.name,()=>{if(!this.built){this.assertInputCompatibility(t);const e=[];for(const n of r.toList(t))e.push(n.shape);this.build(r.singletonOrArray(e)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),null===this._refCount&&a&&(this._refCount=1)}if(this.assertInputCompatibility(t),a){let n=this.call(t,e);const o=r.toList(n),a=[];for(let t of o)-1!==s.indexOf(t)&&(t=t.clone()),a.push(t);if(n=r.singletonOrArray(a),null!=this.activityRegularizer)throw new i.NotImplementedError(\"Layer invocation in the presence of activity regularizer(s) is not supported yet.\");return n}{const n=y(t),s=this.computeOutputShape(n);let o;const a=m(t);if(this.warnOnIncompatibleInputShape(Array.isArray(t)?n[0]:n),o=null!=s&&s.length>0&&Array.isArray(s[0])?s.map((n,i)=>new d(a,n,this,r.toList(t),e,this.name,i)):new d(a,s,this,r.toList(t),e,this.name),this.addInboundNode(t,o,null,null,n,s,e),this._refCount++,null!=this.activityRegularizer)throw new i.NotImplementedError(\"Layer invocation in the presence of activity regularizer(s) is not supported yet.\");return o}})}warnOnIncompatibleInputShape(t){if(null!=this.batchInputShape)if(t.length!==this.batchInputShape.length)console.warn(\"The rank of the input tensor provided (shape: \"+`${JSON.stringify(t)}) does not match that of the `+`batchInputShape (${JSON.stringify(this.batchInputShape)}) `+`of the layer ${this.name}`);else{let e=!1;this.batchInputShape.forEach((n,i)=>{null!=n&&null!=t[i]&&t[i]!==n&&(e=!0)}),e&&console.warn(\"The shape of the input tensor \"+`(${JSON.stringify(t)}) does not `+`match the expectation of layer ${this.name}: `+`${JSON.stringify(this.batchInputShape)}`)}}get outputShape(){if(null==this.inboundNodes||0===this.inboundNodes.length)throw new i.AttributeError(`The layer ${this.name} has never been called and thus has no `+\"defined output shape.\");const t=[];for(const e of this.inboundNodes){const n=JSON.stringify(e.outputShapes);-1===t.indexOf(n)&&t.push(n)}if(1===t.length){const t=this.inboundNodes[0].outputShapes;return Array.isArray(t)&&Array.isArray(t[0])&&1===t.length?t[0]:t}throw new i.AttributeError(`The layer ${this.name} has multiple inbound nodes with different `+'output shapes. Hence the notion of \"output shape\" is ill-defined for the layer.')}countParams(){if(!this.built)throw new i.RuntimeError(`You tried to call countParams() on ${this.name}, `+\"but the layer is not built yet. Build it first by calling build(batchInputShape).\");return a.countParamsInWeights(this.weights)}build(t){this.built=!0}getWeights(t=!1){return(0,h.batchGetValue)(t?this.trainableWeights:this.weights)}setWeights(e){(0,t.tidy)(()=>{const n=this.weights;if(n.length!==e.length)throw new i.ValueError(`You called setWeights(weights) on layer \"${this.name}\" `+`with a weight list of length ${e.length}, `+`but the layer was expecting ${n.length} weights. `+`Provided weights: ${e}...`);if(0===n.length)return;const s=[],r=(0,h.batchGetValue)(n);for(let o=0;o<r.length;++o){const a=r[o],h=n[o],u=e[o];if(!t.util.arraysEqual(a.shape,u.shape))throw new i.ValueError(`Layer weight shape ${a.shape} `+`not compatible with provided weight shape ${u.shape}`);s.push([h,u])}(0,h.batchSetValue)(s)})}addWeight(t,e,n,r,o,a,u){if(-1!==this._addedWeightNames.indexOf(t))throw new i.ValueError(`Duplicate weight name ${t} for layer ${this.name}`);this._addedWeightNames.push(t),null==n&&(n=\"float32\"),this.fastWeightInitDuringBuild&&(r=(0,s.getInitializer)(\"zeros\"));const l=r.apply(e,n),p=new h.LayerVariable(l,n,t,a,u);return l.dispose(),null!=o&&this.addLoss(()=>o.apply(p.read())),null==a&&(a=!0),a?this._trainableWeights.push(p):this._nonTrainableWeights.push(p),p}setFastWeightInitDuringBuild(t){this.fastWeightInitDuringBuild=t}addLoss(t){null==t||Array.isArray(t)&&0===t.length||(t=r.toList(t),void 0!==this._losses&&null!==this._losses&&this.losses.push(...t))}computeOutputShape(t){return t}computeMask(t,e){if(!this.supportsMasking){if(null!=e){if(!Array.isArray(e))throw new TypeError(`Layer ${this.name} does not support masking, `+\"but was passed an inputMask.\");e.forEach(t=>{if(null!=t)throw new TypeError(`Layer ${this.name} does not support masking, `+\"but was passed an inputMask.\")})}return null}return e}addInboundNode(t,e,n,i,s,a,h=null){const u=r.toList(t);e=r.toList(e),n=r.toList(n),i=r.toList(i),s=o.normalizeShapeList(s),a=o.normalizeShapeList(a);const l=[],p=[],d=[];for(const r of u)l.push(r.sourceLayer),p.push(r.nodeIndex),d.push(r.tensorIndex);new f({outboundLayer:this,inboundLayers:l,nodeIndices:p,tensorIndices:d,inputTensors:u,outputTensors:e,inputMasks:n,outputMasks:i,inputShapes:s,outputShapes:a},h);for(let r=0;r<e.length;r++)e[r].sourceLayer=this,e[r].nodeIndex=this.inboundNodes.length-1,e[r].tensorIndex=r}getConfig(){const t={name:this.name,trainable:this.trainable};return null!=this.batchInputShape&&(t.batchInputShape=this.batchInputShape),null!=this.dtype&&(t.dtype=this.dtype),t}disposeWeights(){return this.weights.forEach(t=>t.dispose()),this.weights.length}assertNotDisposed(){if(0===this._refCount)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been `+\"built yet.\");if(null===this._refCount)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used `+\"yet.\");this.assertNotDisposed();let t=0;return 0==--this._refCount&&(t=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:t}}}function y(t){t=r.toList(t);const e=[];for(const n of t)e.push(n.shape);return r.singletonOrArray(e)}function m(t){return\"float32\"}function w(t,e,n){if((null==e||null!=n&&n>0)&&(e=t.sourceLayer,n=t.nodeIndex),0===e.inboundNodes.length)return[t];{const t=e.inboundNodes[n];if(0===t.inboundLayers.length)return t.inputTensors;{const e=[];for(let n=0;n<t.inboundLayers.length;n++){const i=w(t.inputTensors[n],t.inboundLayers[n],t.nodeIndices[n]);for(const t of i)-1===e.indexOf(t)&&e.push(t)}return e}}}exports.Layer=g;"},"sourceMaps":null,"error":null,"hash":"2fe58c49a3fff12159ab2b4c6a0f355f","cacheData":{"env":{}}}