{"id":"Ghc9","dependencies":[{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/package.json","includedInParent":true,"mtime":1609565653941},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":499162500000},{"name":"@tensorflow/tfjs-core","loc":{"line":14,"column":42},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/index.js"},{"name":"../backend/tfjs_backend","loc":{"line":15,"column":19},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/backend/tfjs_backend.js"},{"name":"../engine/topology","loc":{"line":16,"column":22},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js"},{"name":"../errors","loc":{"line":17,"column":48},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/errors.js"},{"name":"../losses","loc":{"line":18,"column":28},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/losses.js"},{"name":"../utils/generic_utils","loc":{"line":19,"column":31},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/generic_utils.js"},{"name":"../utils/math_utils","loc":{"line":20,"column":27},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/math_utils.js"},{"name":"../utils/types_utils","loc":{"line":21,"column":35},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/types_utils.js"}],"generated":{"js":"\"use strict\";Object.defineProperty(exports,\"__esModule\",{value:!0}),exports.add=c,exports.multiply=g,exports.average=m,exports.maximum=x,exports.minimum=w,exports.concatenate=O,exports.Dot=exports.Concatenate=exports.Minimum=exports.Maximum=exports.Average=exports.Multiply=exports.Add=exports.Merge=void 0;var e=u(require(\"@tensorflow/tfjs-core\")),t=u(require(\"../backend/tfjs_backend\")),r=require(\"../engine/topology\"),n=require(\"../errors\"),s=require(\"../losses\"),l=u(require(\"../utils/generic_utils\")),a=u(require(\"../utils/math_utils\")),i=require(\"../utils/types_utils\");function o(){if(\"function\"!=typeof WeakMap)return null;var e=new WeakMap;return o=function(){return e},e}function u(e){if(e&&e.__esModule)return e;if(null===e||\"object\"!=typeof e&&\"function\"!=typeof e)return{default:e};var t=o();if(t&&t.has(e))return t.get(e);var r={},n=Object.defineProperty&&Object.getOwnPropertyDescriptor;for(var s in e)if(Object.prototype.hasOwnProperty.call(e,s)){var l=n?Object.getOwnPropertyDescriptor(e,s):null;l&&(l.get||l.set)?Object.defineProperty(r,s,l):r[s]=e[s]}return r.default=e,t&&t.set(e,r),r}class h extends r.Layer{constructor(e){super(e||{}),this.supportsMasking=!0}mergeFunction(e){throw new n.NotImplementedError}computeElementwiseOpOutputShape(e,t){if(null==e||null==t)return null;if(e.length<t.length)return this.computeElementwiseOpOutputShape(t,e);if(0===t.length)return e;const r=e.slice(0,e.length-t.length);for(let s=0;s<t.length;++s){const l=e[e.length-t.length+s],a=t[s];if(null==l||null==a||l<0||a<0)r.push(null);else if(1===l)r.push(a);else if(1===a)r.push(l);else{if(l!==a)throw new n.ValueError(\"Operands could not be broadcast together with shapes \"+JSON.stringify(e)+\" \"+JSON.stringify(t));r.push(l)}}return r}build(e){if(Array.isArray(e)&&!Array.isArray(e[0])&&(e=[(0,i.getExactlyOneShape)(e)]),(e=e).length<2)throw new n.ValueError(\"A merge layer should be called on an Array of at least 2 inputs.\"+` Got ${e.length} input(s).`);let t=[];for(const n of e)null!=n&&null!==n[0]&&t.push(n[0]);if((t=l.unique(t)).length>1)throw new n.ValueError(\"Can not merge tensors with different batch sizes. \"+`Got tensors with shapes: ${JSON.stringify(e)}.`);let r=null==e[0]?null:e[0].slice(1);for(let n=1;n<e.length;++n){const t=null==e[n]?null:e[n].slice(1);r=this.computeElementwiseOpOutputShape(r,t)}const s=e.map(e=>e.length);-1===e.indexOf(null)&&1===l.unique(s).length?this.reshapeRequired=!1:this.reshapeRequired=!0}call(r,n){return(0,e.tidy)(()=>{if(r=r,this.reshapeRequired){const n=[],s=r.map(e=>e.rank);if(-1===s.indexOf(null)){const e=a.max(s);for(let s of r){const r=s.rank;for(let n=0;n<e-r;++n)s=t.expandDims(s,1);n.push(s)}return this.mergeFunction(n)}{let t=!1;for(const i of r){const r=i.rank;if(null==r){const r=i.shape,s=r[0],l=r.slice(1).concat([s]);let o=i.reshape([s].concat(a.arrayProd(r.slice(1))));o=(o=e.transpose(o,[1,0])).reshape(l),n.push(o),t=!0}else if(r>1){const s=a.range(1,r).concat([0]);n.push(e.transpose(i,s)),t=!0}else n.push(i)}let s=this.mergeFunction(n);const l=s.rank;if(t)if(null==l){const t=s.shape,r=t[t.length-1],n=[r].concat(t.slice(0,t.length-1));s=e.transpose(s.reshape([-1,r]),[1,0]).reshape(n)}else if(l>1){const t=[l-1].concat(a.range(0,l-1));s=e.transpose(s,t)}return s}}return this.mergeFunction(r)})}computeOutputShape(e){let t;t=null==(e=e)[0]?null:e[0].slice(1);for(let n=1;n<e.length;++n){const r=null==e[n]?null:e[n].slice(1);t=this.computeElementwiseOpOutputShape(t,r)}let r=[];for(const n of e)null!=n&&null!==n[0]&&r.push(n[0]);return t=1===(r=l.unique(r)).length?r.concat(t):[null].concat(t)}computeMask(t,r){return e.tidy(()=>{if(null==r)return null;if(!Array.isArray(r))throw new n.ValueError(\"`mask` should be an Array\");if(!Array.isArray(t))throw new n.ValueError(\"`inputs` should be an Array\");if(r.length!==t.length)throw new n.ValueError(\"The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths \"+`(${t.length} vs ${r.length})`);if(r.every(e=>null==e))return null;let s=(r=r.map(t=>null==t?t:e.expandDims(t,0)))[0];for(let t=1;t<r.length-1;++t)s=e.logicalAnd(s,r[t]);return s})}}exports.Merge=h;class p extends h{constructor(e){super(e)}mergeFunction(t){return(0,e.tidy)(()=>{let r=t[0].clone();for(let n=1;n<t.length;++n)r=e.add(r,t[n]);return r})}}function c(e){if(Array.isArray(e)){return new p({}).apply(e)}return new p(e)}exports.Add=p,p.className=\"Add\",e.serialization.registerClass(p);class f extends h{constructor(e){super(e)}mergeFunction(t){return(0,e.tidy)(()=>{let r=t[0].clone();for(let n=1;n<t.length;++n)r=e.mul(r,t[n]);return r})}}function g(e){if(Array.isArray(e)){return new f({}).apply(e)}return new f(e)}exports.Multiply=f,f.className=\"Multiply\",e.serialization.registerClass(f);class y extends h{constructor(e){super(e)}mergeFunction(t){return(0,e.tidy)(()=>{let r=t[0].clone();for(let n=1;n<t.length;++n)r=e.add(r,t[n]);return e.mul(1/t.length,r)})}}function m(e){if(Array.isArray(e)){return new y({}).apply(e)}return new y(e)}exports.Average=y,y.className=\"Average\",e.serialization.registerClass(y);class d extends h{constructor(e){super(e)}mergeFunction(t){return(0,e.tidy)(()=>{let r=t[0];for(let n=1;n<t.length;++n)r=e.maximum(r,t[n]);return r})}}function x(e){if(Array.isArray(e)){return new d({}).apply(e)}return new d(e)}exports.Maximum=d,d.className=\"Maximum\",e.serialization.registerClass(d);class A extends h{constructor(e){super(e)}mergeFunction(t){return(0,e.tidy)(()=>{let r=t[0];for(let n=1;n<t.length;++n)r=e.minimum(r,t[n]);return r})}}function w(e){if(Array.isArray(e)){return new A({}).apply(e)}return new A(e)}exports.Minimum=A,A.className=\"Minimum\",e.serialization.registerClass(A);class b extends h{constructor(e){super(e),this.DEFAULT_AXIS=-1,null==e&&(e={}),this.axis=null==e.axis?this.DEFAULT_AXIS:e.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){if(!Array.isArray(t)||!Array.isArray(t[0])||1===t.length)throw new n.ValueError(\"A `Concatenate` layer should be called on a list of at least 2 inputs\");t=t;let r=!0;for(const e of t)if(null!=e){r=!1;break}if(r)return;const s=[];for(let n=0;n<t.length;++n){const r=t[n].slice();r.splice(this.axis,1);let l=!1;for(const t of s)if(e.util.arraysEqual(t,r)){l=!0;break}l||s.push(r)}if(s.length>1)throw new n.ValueError(\"A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: \"+JSON.stringify(t))}mergeFunction(r){return(0,e.tidy)(()=>t.concatenate(r,this.axis))}computeOutputShape(e){if(!Array.isArray(e)||!Array.isArray(e[0]))throw new n.ValueError(\"A `Concatenate` layer should be called on a list of inputs.\");const t=e,r=t[0].slice(),s=this.axis<0?r.length+this.axis:this.axis;for(const n of t.slice(1)){if(null==r[s]||null==n[s]){r[s]=null;break}r[s]+=n[s]}return r}computeMask(t,r){if(null==r)return null;if(!Array.isArray(r))throw new n.ValueError(\"`mask` should be an array for Concatenate\");if(!Array.isArray(t))throw new n.ValueError(\"`inputs` should be an array for Concatenate\");if(r.length!==t.length)throw new n.ValueError(`Mismatch in the length of mask (${r.length}) `+`and the legnth of inputs (${t.length})`);return e.tidy(()=>{let n=!0;if(r.forEach(e=>{null==e||(n=!1)}),n)return null;const s=[];for(let a=0;a<t.length;++a)null==r[a]?s.push(e.onesLike(t[a]).asType(\"bool\")):r[a].rank<t[a].rank?s.push(e.expandDims(r[a],-1)):s.push(r[a]);const l=e.concat(s,this.axis);return e.all(l,-1,!1)})}getConfig(){const e={axis:this.axis},t=super.getConfig();return Object.assign(e,t),e}}function O(e){if(Array.isArray(e)){return new b({}).apply(e)}return new b(e)}function k(e,t){for(;e<0;)e+=t;return e}function E(t,r,s){if(t.shape.length>3||r.shape.length>3)throw new n.NotImplementedError(\"batchDot is not implemented for tensors of 4D or higher rank yet\");if(e.util.assert(t.shape.length>=2,()=>\"batchDot requires the rank of x to be >= 2, \"+`but got ${t.shape.length}`),e.util.assert(t.shape.length>=2,()=>\"batchDot requires the rank of y to be >= 2, \"+`but got ${r.shape.length}`),\"number\"==typeof s&&(s=[s,s]),\"complex64\"===t.dtype||\"complex64\"===r.dtype)throw new n.NotImplementedError(\"batchDot is not implemented for complex64-type Tensors yet.\");const l=t.shape.length,a=r.shape.length;null==s&&(s=[l-1,a-2]);const i=s;return e.tidy(()=>{let e,n;if(l>a){e=l-a;const t=[];for(let r=0;r<e;++r)t.push(1);r=r.reshape(r.shape.concat(t))}else if(a>l){e=a-l;const r=[];for(let t=0;t<e;++t)r.push(1);t=t.reshape(t.shape.concat(r))}else e=0;if(2===t.shape.length&&2===r.shape.length)n=i[0]===i[1]?t.mul(r).sum(i[0]):t.transpose([1,0]).mul(r).sum(i[1]);else{const e=i[0]!==t.shape.length-1,s=i[1]===r.shape.length-1;n=t.matMul(r,e,s)}if(e>0){let t;const r=[];for(let n=t=l>a?l+a-3:l-1;n<t+e;++n)r.push(n);n=n.squeeze(r)}return 1===n.shape.length&&(n=n.expandDims(1)),n})}exports.Concatenate=b,b.className=\"Concatenate\",e.serialization.registerClass(b);class D extends h{constructor(e){super(e),this.axes=e.axes,this.normalize=null!=e.normalize&&e.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){e.util.assert(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),()=>\"A `Dot` layer should be called on a list of exactly 2 inputs.\");const r=t[0],s=t[1];if(r.length>3||s.length>3)throw new n.NotImplementedError(\"Dot layer does not support tensors of 4D or higher rank yet.\");const l=this.interpretAxes(r,s);if(r[l[0]]!==s[l[1]])throw new n.ValueError(\"Dimension incompatibility: \"+`${r[l[0]]} !== ${s[l[1]]}`)}mergeFunction(e){if(2!==e.length)throw new n.ValueError(\"A `Dot` layer must be called on exactly 2 inputs, \"+`but received ${e.length} input(s).`);let t,r=e[0],l=e[1];return t=Array.isArray(this.axes)?this.axes.map((t,r)=>k(t,e[r].shape.length)):[k(this.axes,r.shape.length),k(this.axes,l.shape.length)],this.normalize&&(r=(0,s.l2Normalize)(r,t[0]),l=(0,s.l2Normalize)(l,t[1])),E(r,l,t)}interpretAxes(e,t){let r;return r=Array.isArray(this.axes)?this.axes:[k(this.axes,e.length),k(this.axes,t.length)]}computeOutputShape(t){e.util.assert(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),()=>\"A `Dot` layer should be called on a list of exactly 2 inputs.\");const r=t[0].slice(),s=t[1].slice();if(r.length>3||s.length>3)throw new n.NotImplementedError(\"Dot layer does not support tensors of 4D or higher rank yet.\");const l=this.interpretAxes(r,s);r.splice(l[0],1),s.splice(l[1],1),s.splice(0,1);const a=r.concat(s);return 1===a.length&&a.push(1),a}computeMask(e,t){return null}getConfig(){const e={axes:this.axes,normalize:this.normalize},t=super.getConfig();return Object.assign(e,t),e}}exports.Dot=D,D.className=\"Dot\",e.serialization.registerClass(D);"},"sourceMaps":null,"error":null,"hash":"bfbeee1951fa1a0a61ed6132a0cd651b","cacheData":{"env":{}}}