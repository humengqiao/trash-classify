{"id":"sRwx","dependencies":[{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/package.json","includedInParent":true,"mtime":1609564004117},{"name":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":499162500000},{"name":"@tensorflow/tfjs-core","loc":{"line":14,"column":39},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/training_tensors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-core/dist/index.js"},{"name":"../backend/tfjs_backend","loc":{"line":15,"column":56},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/training_tensors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/backend/tfjs_backend.js"},{"name":"../base_callbacks","loc":{"line":16,"column":57},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/training_tensors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/base_callbacks.js"},{"name":"../errors","loc":{"line":17,"column":48},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/training_tensors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/errors.js"},{"name":"../logs","loc":{"line":18,"column":37},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/training_tensors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/logs.js"},{"name":"../utils/math_utils","loc":{"line":19,"column":22},"parent":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/engine/training_tensors.js","resolved":"/Users/humengqiao/Desktop/node-project/trash-classify/node_modules/@tensorflow/tfjs-layers/dist/utils/math_utils.js"}],"generated":{"js":"\"use strict\";Object.defineProperty(exports,\"__esModule\",{value:!0}),exports.checkBatchSize=l,exports.sliceArrays=c,exports.sliceArraysByIndices=u,exports.makeBatches=p,exports.fitTensors=d,exports.ensureTensorsRank2OrHigher=h,exports.disposeNewTensors=g;var e=o(require(\"@tensorflow/tfjs-core\")),t=require(\"../backend/tfjs_backend\"),n=require(\"../base_callbacks\"),i=require(\"../errors\"),a=require(\"../logs\"),r=require(\"../utils/math_utils\");function s(){if(\"function\"!=typeof WeakMap)return null;var e=new WeakMap;return s=function(){return e},e}function o(e){if(e&&e.__esModule)return e;if(null===e||\"object\"!=typeof e&&\"function\"!=typeof e)return{default:e};var t=s();if(t&&t.has(e))return t.get(e);var n={},i=Object.defineProperty&&Object.getOwnPropertyDescriptor;for(var a in e)if(Object.prototype.hasOwnProperty.call(e,a)){var r=i?Object.getOwnPropertyDescriptor(e,a):null;r&&(r.get||r.set)?Object.defineProperty(n,a,r):n[a]=e[a]}return n.default=e,t&&t.set(e,n),n}function l(t){e.util.assert(t>0&&Number.isInteger(t),()=>`batchSize is required to be a positive integer, but got ${t}`)}function c(e,n,i){return null==e?[null]:Array.isArray(e)?e.map(e=>(0,t.sliceAlongFirstAxis)(e,n,i-n)):(0,t.sliceAlongFirstAxis)(e,n,i-n)}function u(n,i){return e.tidy(()=>null==n?null:Array.isArray(n)?n.map(e=>u(e,i)):(0,t.gather)(n,\"int32\"===i.dtype?i:i.toInt()))}function p(e,t){const n=[];let i=0,a=null;for(;i<e;)(a=i+t)>=e&&(a=e),n.push([i,a]),i=a;return n}async function f(s,o,l,c,f,d,h,g,y,v,b,w,m,k,E){null==f&&(f=32),null==d&&(d=1),null==b&&(b=!0),null==m&&(m=0);let D=!1;if(null!=y&&null!=v&&(D=!0),null!=E&&(D=!0,null==k))throw new i.ValueError(\"Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.\");const T=s.checkNumSamples(l,f,k,\"steps_per_epoch\");let x;null!=T&&(x=(0,r.range)(0,T)),null==h&&(h=1);const{callbackList:A,history:_}=(0,n.configureCallbacks)(g,h,d,m,T,k,f,D,w);A.setModel(s),s.history=_,await A.onTrainBegin(),s.stopTraining_=!1;for(let n=m;n<d;++n){await A.onEpochBegin(n);const r={};if(null!=k)throw new i.NotImplementedError(\"stepsPerEpoch mode is not implemented yet.\");{if(\"batch\"===b)throw new i.NotImplementedError(\"batch shuffling is not implemneted yet\");b&&e.util.shuffle(x);const n=(0,e.tensor1d)(x),d=p(T,f);for(let i=0;i<d.length;++i){const p={};if(await A.onBatchBegin(i,p),e.tidy(()=>{const a=d[i][0],h=d[i][1],g=(0,t.sliceAlongFirstAxis)(n,a,h-a);p.batch=i,p.size=h-a;const b=u(l,g),w=o(b);for(let t=0;t<c.length;++t){const n=c[t],i=w[t];p[n]=i,e.keep(i)}if(i===d.length-1&&D){const t=s.testLoop(y,v,f);for(let n=0;n<c.length;++n){const i=c[n],a=t[n];e.keep(a),r[\"val_\"+i]=a}}}),await A.onBatchEnd(i,p),(0,a.disposeTensorsInLogs)(p),s.stopTraining_)break}n.dispose()}if(await A.onEpochEnd(n,r),s.stopTraining_)break}return await A.onTrainEnd(),await s.history.syncData(),s.history}async function d(t,a,r,s={}){if(t.isTraining)throw new Error(\"Cannot start training because another fit() call is ongoing.\");let o,u,p,d,h,y,v;t.isTraining=!0;try{const b=null==s.batchSize?32:s.batchSize;l(b);const w=!1,m=await t.standardizeUserData(a,r,s.sampleWeight,s.classWeight,w,b);o=m[0],u=m[1],v=m[2];let k,E=!1;if(null!=s.validationData&&s.validationData.length>0){if(E=!0,2!==s.validationData.length)throw 3===s.validationData.length?new i.NotImplementedError(\"validationData including sample weights is not supported yet.\"):new i.ValueError(\"When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; \"+`${s.validationData} is invalid.`);p=s.validationData[0],d=s.validationData[1];const e=!0,n=await t.standardizeUserData(p,d,null,null,e,b);h=n[0],y=n[1],k=h.concat(y)}else if(null!=s.validationSplit&&s.validationSplit>0&&s.validationSplit<1){E=!0;const e=Math.floor(o[0].shape[0]*(1-s.validationSplit)),t=o[0].shape[0];h=c(o,e,t),o=c(o,0,e),y=c(u,e,t),u=c(u,0,e),k=h.concat(y)}else null!=s.validationSteps&&(E=!0);const D=o.concat(u).concat(v);t.checkTrainableWeightsConsistency();const T=t.makeTrainFunction(),x=t.getDedupedMetricsNames();let A,_;E?(t.makeTestFunction(),A=t.testFunction,_=x.slice().concat(x.map(e=>\"val_\"+e))):(A=null,k=[],_=x.slice());const O=(0,n.standardizeCallbacks)(s.callbacks,s.yieldEvery);return await f(t,T,D,x,b,s.epochs,s.verbose,O,A,k,s.shuffle,_,s.initialEpoch,null,null)}finally{t.isTraining=!1,g(o,a),g(u,r),g(h,p),g(y,d),null!=v&&e.dispose(v)}}function h(n){const i=[];n instanceof e.Tensor&&(n=[n]);for(let e=0;e<n.length;++e){const a=n[e];if(1===a.rank)i.push((0,t.expandDims)(a,1));else{if(0===a.rank)throw new Error(\"Expected tensor to be at least 1D, but received a 0D tensor (scalar).\");i.push(a)}}return i}function g(t,n){if(null==t)return;const i=[];if(n instanceof e.Tensor)i.push(n.id);else if(Array.isArray(n))n.forEach(e=>i.push(e.id));else if(null!=n)for(const e in n){const t=n[e];i.push(t.id)}const a=[];if(t instanceof e.Tensor)-1===i.indexOf(t.id)&&a.push(t);else if(Array.isArray(t))t.forEach(e=>{-1===i.indexOf(e.id)&&a.push(e)});else if(null!=t)for(const e in t){const n=t[e];-1===i.indexOf(n.id)&&a.push(n)}a.forEach(e=>{e.isDisposed||e.dispose()})}"},"sourceMaps":null,"error":null,"hash":"bceecac56452869f3e2e6cde6c763629","cacheData":{"env":{}}}